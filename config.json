{
    "model": "gpt-4o",
    "temperature": 0.7,
    "max_tokens": 2048
}